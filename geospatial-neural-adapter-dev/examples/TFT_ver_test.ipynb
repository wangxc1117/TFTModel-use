{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLS vs. Spatial Adapter Comparison with Tuning Parameter Selection\n",
    "\n",
    "This notebook implements a comprehensive comparison between:\n",
    "1. **OLS (Ordinary Least Squares)** - Linear baseline\n",
    "2. **Unregularized Spatial Adapter** - Neural spatial model without regularization\n",
    "3. **Regularized Spatial Adapter** - Neural spatial model with optimized tau1, tau2 parameters\n",
    "\n",
    "The experiment uses Optuna for hyperparameter optimization and evaluates performance across multiple random seeds.\n",
    "\n",
    "my work: ols æ›æˆ TFT ç„¶å¾ŒåŸ·è¡Œæ¨¡æ“¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "345997df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wangxc17/miniconda/envs/geospatial-neural-adapter/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loaded spatial_utils from: /home/wangxc17/work/TFTModel-use/geospatial-neural-adapter-dev/geospatial_neural_adapter/cpp_extensions/spatial_utils.so\n",
      "âœ… All imports successful!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wangxc17/miniconda/envs/geospatial-neural-adapter/lib/python3.12/site-packages/fs/__init__.py:4: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  __import__(\"pkg_resources\").declare_namespace(__name__)  # type: ignore\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import csv\n",
    "import math\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import optuna\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from optuna.pruners import MedianPruner\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from typing import Tuple, Dict, Any\n",
    "import pandas as pd\n",
    "\n",
    "# NEW: Darts TFT backbone\n",
    "from darts import TimeSeries\n",
    "from darts.models import TFTModel\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from geospatial_neural_adapter.cpp_extensions import estimate_covariance\n",
    "from geospatial_neural_adapter.utils.experiment import log_covariance_and_basis\n",
    "from geospatial_neural_adapter.utils import (\n",
    "    ModelCache,\n",
    "    clear_gpu_memory,\n",
    "    create_experiment_config,\n",
    "    print_experiment_summary,\n",
    "    get_device_info,\n",
    ")\n",
    "from geospatial_neural_adapter.models.spatial_basis_learner import SpatialBasisLearner\n",
    "from geospatial_neural_adapter.models.spatial_neural_adapter import SpatialNeuralAdapter\n",
    "\n",
    "# NEW: ç”¨ TFT ç•¶ backbone çš„åŒ…è£\n",
    "from geospatial_neural_adapter.models.pretrained_trend_model import create_pretrained_trend_model\n",
    "from geospatial_neural_adapter.models.wrapper_examples.tft_wrapper import TFTWrapper\n",
    "\n",
    "from geospatial_neural_adapter.data.generators import generate_time_synthetic_data\n",
    "from geospatial_neural_adapter.data.preprocessing import prepare_all_with_scaling, denormalize_predictions\n",
    "from geospatial_neural_adapter.metrics import compute_metrics\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"âœ… All imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f86c36",
   "metadata": {},
   "source": [
    "## 1. Parameter Configuration and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba4dfeda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-11 15:47:20,407 - spatial_neural_adapter - INFO - SpatialNeuralAdapterConfig:\n",
      "2025-08-11 15:47:20,408 - spatial_neural_adapter - INFO -   ADMM Config:\n",
      "2025-08-11 15:47:20,408 - spatial_neural_adapter - INFO -     rho: 1.0\n",
      "2025-08-11 15:47:20,408 - spatial_neural_adapter - INFO -     dual_momentum: 0.2\n",
      "2025-08-11 15:47:20,409 - spatial_neural_adapter - INFO -     max_iters: 3000\n",
      "2025-08-11 15:47:20,409 - spatial_neural_adapter - INFO -     min_outer: 20\n",
      "2025-08-11 15:47:20,409 - spatial_neural_adapter - INFO -     tol: 0.0001\n",
      "2025-08-11 15:47:20,410 - spatial_neural_adapter - INFO -   Training Config:\n",
      "2025-08-11 15:47:20,410 - spatial_neural_adapter - INFO -     lr_mu: 0.01\n",
      "2025-08-11 15:47:20,410 - spatial_neural_adapter - INFO -     batch_size: 64\n",
      "2025-08-11 15:47:20,411 - spatial_neural_adapter - INFO -     pretrain_epochs: 5\n",
      "2025-08-11 15:47:20,411 - spatial_neural_adapter - INFO -     use_mixed_precision: False\n",
      "2025-08-11 15:47:20,411 - spatial_neural_adapter - INFO -   Basis Config:\n",
      "2025-08-11 15:47:20,412 - spatial_neural_adapter - INFO -     phi_every: 5\n",
      "2025-08-11 15:47:20,412 - spatial_neural_adapter - INFO -     phi_freeze: 200\n",
      "2025-08-11 15:47:20,412 - spatial_neural_adapter - INFO -     matrix_reg: 1e-06\n",
      "2025-08-11 15:47:20,412 - spatial_neural_adapter - INFO -     irl1_max_iters: 10\n",
      "2025-08-11 15:47:20,413 - spatial_neural_adapter - INFO -     irl1_eps: 1e-06\n",
      "2025-08-11 15:47:20,413 - spatial_neural_adapter - INFO -     irl1_tol: 0.0005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA: NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "   Memory: 8.6 GB\n",
      "\n",
      "=== Experiment Configuration ===\n",
      "seed: 42\n",
      "n_time_steps: 1024\n",
      "n_locations: 512\n",
      "noise_std: 4.0\n",
      "eigenvalue: 16.0\n",
      "latent_dim: 1\n",
      "ckpt_dir: admm_bcd_ckpts\n",
      "\n",
      "=== Spatial Neural Adapter Configuration ===\n"
     ]
    }
   ],
   "source": [
    "# Experiment Configuration\n",
    "EXPERIMENT_CONFIG = {\n",
    "    'seed': 42,\n",
    "    'n_time_steps': 1024,\n",
    "    'n_locations': 512,\n",
    "    'noise_std': 4.0,\n",
    "    'eigenvalue': 16.0,\n",
    "    'latent_dim': 1,\n",
    "    'ckpt_dir': \"admm_bcd_ckpts\",\n",
    "}\n",
    "\n",
    "TFT_CONFIG = {\n",
    "    # é•·åº¦\n",
    "    'tft_input_chunk_length': None,  # None â†’ ä¾ T_train è‡ªå‹•ç®—\n",
    "    'tft_output_chunk_length': 1,\n",
    "    'tft_output_chunk_shift': 0,\n",
    "\n",
    "    # æ¨¡å‹è¦æ¨¡\n",
    "    'tft_hidden_size': 16, #32         \n",
    "    'tft_lstm_layers': 1,            \n",
    "    'tft_num_attention_heads': 2,    \n",
    "    'tft_full_attention': False,\n",
    "    'tft_feed_forward': 'GatedResidualNetwork',\n",
    "    'tft_hidden_continuous_size': 16,             \n",
    "\n",
    "    # è¨“ç·´/å„ªåŒ–\n",
    "    'tft_batch_size': 16, # 64\n",
    "    'tft_n_epochs': 5, #20\n",
    "    'tft_optimizer_kwargs': {'lr': 1e-3, 'weight_decay': 1e-4},\n",
    "}\n",
    "\n",
    "# Spatial Neural Adapter Configuration using dataclasses\n",
    "from geospatial_neural_adapter.models.spatial_neural_adapter import (\n",
    "    SpatialNeuralAdapterConfig, ADMMConfig, TrainingConfig, BasisConfig\n",
    ")\n",
    "\n",
    "# ADMM Configuration\n",
    "admm_config = ADMMConfig(\n",
    "    rho=1.0,\n",
    "    dual_momentum=0.2,\n",
    "    max_iters=3000,\n",
    "    min_outer=20,\n",
    "    tol=1e-4,\n",
    ")\n",
    "\n",
    "# Training Configuration\n",
    "training_config = TrainingConfig(\n",
    "    lr_mu=1e-2,\n",
    "    batch_size=64,\n",
    "    pretrain_epochs=5,\n",
    "    use_mixed_precision=False,\n",
    ")\n",
    "\n",
    "# Basis Configuration\n",
    "basis_config = BasisConfig(\n",
    "    phi_every=5,\n",
    "    phi_freeze=200,\n",
    "    matrix_reg=1e-6,\n",
    "    irl1_max_iters=10,\n",
    "    irl1_eps=1e-6,\n",
    "    irl1_tol=5e-4,\n",
    ")\n",
    "\n",
    "# Complete Spatial Neural Adapter Configuration\n",
    "SPATIAL_CONFIG = SpatialNeuralAdapterConfig(\n",
    "    admm=admm_config,\n",
    "    training=training_config,\n",
    "    basis=basis_config\n",
    ")\n",
    "\n",
    "# Legacy dict for convenience\n",
    "CFG: Dict[str, Any] = SPATIAL_CONFIG.to_dict()\n",
    "CFG.update(EXPERIMENT_CONFIG)\n",
    "CFG.update(TFT_CONFIG) \n",
    "\n",
    "# Set random seed & paths\n",
    "torch.manual_seed(EXPERIMENT_CONFIG[\"seed\"])\n",
    "Path(EXPERIMENT_CONFIG[\"ckpt_dir\"]).mkdir(exist_ok=True)\n",
    "\n",
    "# Device setup\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device_info = get_device_info()\n",
    "print(f\"Using {device_info['device'].upper()}: {device_info['device_name']}\")\n",
    "if device_info['device'] == 'cuda':\n",
    "    print(f\"   Memory: {device_info['memory_gb']} GB\")\n",
    "\n",
    "# Print configuration summary\n",
    "print(\"\\n=== Experiment Configuration ===\")\n",
    "for key, value in EXPERIMENT_CONFIG.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "print(\"\\n=== Spatial Neural Adapter Configuration ===\")\n",
    "SPATIAL_CONFIG.log_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a32565",
   "metadata": {},
   "source": [
    "## 2. Initialize Utilities\n",
    " ç›®å‰æ¸›å°‘è·‘çš„æ¬¡æ•¸ ç¢ºèªå®Œä¹‹å¾Œè¦è·‘å®Œæ•´çš„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c16d3a14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment Configuration:\n",
      "  Trials per seed: 5\n",
      "  Dataset seeds: 1 to 2\n",
      "  Total experiments: 10\n",
      "  Device: GPU\n",
      "Utilities initialized successfully!\n"
     ]
    }
   ],
   "source": [
    "# Initialize model cache for hyperparameter optimization\n",
    "cache = ModelCache()\n",
    "\n",
    "# Create experiment configuration\n",
    "EXPERIMENT_TRIALS_CONFIG = create_experiment_config(\n",
    "    n_trials_per_seed=5 if torch.cuda.is_available() else 5,\n",
    "    n_dataset_seeds=2,\n",
    "    seed_range_start=1,\n",
    "    seed_range_end=3,\n",
    ")\n",
    "\n",
    "print_experiment_summary(EXPERIMENT_TRIALS_CONFIG)\n",
    "print(\"Utilities initialized successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7777490a",
   "metadata": {},
   "source": [
    "## 3. Data Generation and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c19da385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating correlated synthetic data...\n",
      "Data shapes: cont=(1024, 512, 3), targets=(1024, 512)\n",
      "Original targets - Mean: 50.95, Std: 4.22\n",
      "Original targets - Range: 31.31 to 72.22\n",
      "N = 512 | F = 3 | T = 1024\n"
     ]
    }
   ],
   "source": [
    "# Generate synthetic data with meaningful correlations\n",
    "print(\"Generating correlated synthetic data...\")\n",
    "\n",
    "locs = np.linspace(-3, 3, CFG[\"n_locations\"]).astype(np.float32)\n",
    "\n",
    "cat_features, cont_features, targets = generate_time_synthetic_data(\n",
    "    locs=locs,\n",
    "    n_time_steps=CFG[\"n_time_steps\"],\n",
    "    noise_std=CFG[\"noise_std\"],\n",
    "    eigenvalue=CFG[\"eigenvalue\"],\n",
    "    eta_rho=0.8,\n",
    "    f_rho=0.6,\n",
    "    global_mean=50.0,\n",
    "    feature_noise_std=0.1,\n",
    "    non_linear_strength=0.2,\n",
    "    seed=CFG[\"seed\"],\n",
    ")\n",
    "\n",
    "train_dataset, val_dataset, test_dataset, preprocessor = prepare_all_with_scaling(\n",
    "    cat_features=cat_features,\n",
    "    cont_features=cont_features,\n",
    "    targets=targets,\n",
    "    train_ratio=0.7,\n",
    "    val_ratio=0.15,\n",
    "    feature_scaler_type=\"standard\",\n",
    "    target_scaler_type=\"standard\",\n",
    "    fit_on_train_only=True,\n",
    ")\n",
    "\n",
    "# å»º DataLoaderï¼šç”¨ SPATIAL_CONFIG.training.batch_size åšä¿éšª\n",
    "bs = int(CFG.get(\"batch_size\", SPATIAL_CONFIG.training.batch_size))\n",
    "train_loader = DataLoader(train_dataset, batch_size=bs, shuffle=True)\n",
    "\n",
    "# Extract tensors\n",
    "_, train_X, train_y = train_dataset.tensors\n",
    "_, val_X,   val_y   = val_dataset.tensors\n",
    "_, test_X,  test_y  = test_dataset.tensors\n",
    "\n",
    "p_dim  = train_X.shape[-1]\n",
    "T_full = cont_features.shape[0]\n",
    "N      = cont_features.shape[1]\n",
    "F      = p_dim\n",
    "\n",
    "print(f\"Data shapes: cont={cont_features.shape}, targets={targets.shape}\")\n",
    "print(f\"Original targets - Mean: {targets.mean():.2f}, Std: {targets.std():.2f}\")\n",
    "print(f\"Original targets - Range: {targets.min():.2f} to {targets.max():.2f}\")\n",
    "print(f\"N = {N} | F = {F} | T = {T_full}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb14f9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Visualize data characteristics\n",
    "# fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# # Plot 1: Target distribution\n",
    "# axes[0, 0].hist(targets.flatten(), bins=30, alpha=0.7, edgecolor='black')\n",
    "# axes[0, 0].set_title('Target Distribution')\n",
    "# axes[0, 0].set_xlabel('Target Value')\n",
    "# axes[0, 0].set_ylabel('Frequency')\n",
    "# axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# # Plot 2: Spatial pattern at first time step\n",
    "# axes[0, 1].plot(locs, targets[0, :], 'o-', linewidth=2, markersize=4)\n",
    "# axes[0, 1].set_title('Spatial Pattern at t=0')\n",
    "# axes[0, 1].set_xlabel('Location')\n",
    "# axes[0, 1].set_ylabel('Target Value')\n",
    "# axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# # Plot 3: Temporal pattern at middle location\n",
    "# time_steps = np.arange(len(targets))\n",
    "# axes[1, 0].plot(time_steps, targets[:, 25], linewidth=2)\n",
    "# axes[1, 0].set_title('Temporal Pattern at Location 25')\n",
    "# axes[1, 0].set_xlabel('Time Step')\n",
    "# axes[1, 0].set_ylabel('Target Value')\n",
    "# axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# # Plot 4: Feature correlations\n",
    "# feature_corrs = []\n",
    "# for i in range(cont_features.shape[-1]):\n",
    "#     corr = np.corrcoef(targets.flatten(), cont_features[:, :, i].flatten())[0, 1]\n",
    "#     feature_corrs.append(corr)\n",
    "\n",
    "# axes[1, 1].bar(range(len(feature_corrs)), feature_corrs, alpha=0.7, edgecolor='black')\n",
    "# axes[1, 1].set_title('Feature-Target Correlations')\n",
    "# axes[1, 1].set_xlabel('Feature Index')\n",
    "# axes[1, 1].set_ylabel('Correlation')\n",
    "# axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7fb6b7",
   "metadata": {},
   "source": [
    "## 4. Baseline Implementation\n",
    " OLS æ”¹æˆ TFT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016d8ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training TFT baseline...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4060 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name                              | Type                             | Params | Mode \n",
      "------------------------------------------------------------------------------------------------\n",
      "0  | train_metrics                     | MetricCollection                 | 0      | train\n",
      "1  | val_metrics                       | MetricCollection                 | 0      | train\n",
      "2  | input_embeddings                  | _MultiEmbedding                  | 0      | train\n",
      "3  | static_covariates_vsn             | _VariableSelectionNetwork        | 0      | train\n",
      "4  | encoder_vsn                       | _VariableSelectionNetwork        | 3.7 M  | train\n",
      "5  | decoder_vsn                       | _VariableSelectionNetwork        | 1.2 K  | train\n",
      "6  | static_context_grn                | _GatedResidualNetwork            | 1.1 K  | train\n",
      "7  | static_context_hidden_encoder_grn | _GatedResidualNetwork            | 1.1 K  | train\n",
      "8  | static_context_cell_encoder_grn   | _GatedResidualNetwork            | 1.1 K  | train\n",
      "9  | static_context_enrichment         | _GatedResidualNetwork            | 1.1 K  | train\n",
      "10 | lstm_encoder                      | LSTM                             | 2.2 K  | train\n",
      "11 | lstm_decoder                      | LSTM                             | 2.2 K  | train\n",
      "12 | post_lstm_gan                     | _GateAddNorm                     | 576    | train\n",
      "13 | static_enrichment_grn             | _GatedResidualNetwork            | 1.4 K  | train\n",
      "14 | multihead_attn                    | _InterpretableMultiHeadAttention | 808    | train\n",
      "15 | post_attn_gan                     | _GateAddNorm                     | 576    | train\n",
      "16 | feed_forward_block                | _GatedResidualNetwork            | 1.1 K  | train\n",
      "17 | pre_output_gan                    | _GateAddNorm                     | 576    | train\n",
      "18 | output_layer                      | Linear                           | 147 K  | train\n",
      "------------------------------------------------------------------------------------------------\n",
      "3.9 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.9 M     Total params\n",
      "15.477    Total estimated model params size (MB)\n",
      "28305     Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 43/43 [01:51<00:00,  0.39it/s, train_loss=4.130]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 43/43 [01:51<00:00,  0.39it/s, train_loss=4.130]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "PretrainedTrendModel.__init__() got an unexpected keyword argument 'device'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 65\u001b[39m\n\u001b[32m     63\u001b[39m \u001b[38;5;66;03m# Wrap TFT as trend model for Spatial Adapter\u001b[39;00m\n\u001b[32m     64\u001b[39m tft_wrapper = TFTWrapper(tft_model=tft_model, num_locations=N, num_features=F)\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m tft_trend = \u001b[43mcreate_pretrained_trend_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpretrained_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtft_wrapper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mF\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;66;43;03m# â† è¼¸å…¥ï¼šT x N x F\u001b[39;49;00m\n\u001b[32m     68\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_shape\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# â† è¼¸å‡ºï¼šT x N x 1\u001b[39;49;00m\n\u001b[32m     69\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mDEVICE\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[38;5;66;03m# Residual eigen-basis from validation residuals\u001b[39;00m\n\u001b[32m     73\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/TFTModel-use/geospatial-neural-adapter-dev/geospatial_neural_adapter/models/pretrained_trend_model.py:242\u001b[39m, in \u001b[36mcreate_pretrained_trend_model\u001b[39m\u001b[34m(pretrained_model, input_shape, output_shape, model_type, **kwargs)\u001b[39m\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m model_type \u001b[38;5;129;01min\u001b[39;00m output_adapters:\n\u001b[32m    240\u001b[39m     kwargs.setdefault(\u001b[33m\"\u001b[39m\u001b[33moutput_adapter\u001b[39m\u001b[33m\"\u001b[39m, output_adapters[model_type])\n\u001b[32m--> \u001b[39m\u001b[32m242\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPretrainedTrendModel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    243\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpretrained_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpretrained_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    244\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    245\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_shape\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_shape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    246\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    247\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: PretrainedTrendModel.__init__() got an unexpected keyword argument 'device'"
     ]
    }
   ],
   "source": [
    "# Compute true spatial basis for comparison\n",
    "phi_true = np.exp(-(locs**2))[:, None]\n",
    "phi_true /= np.linalg.norm(phi_true)\n",
    "sigma_true_spatial = CFG[\"eigenvalue\"] * (phi_true @ phi_true.T)\n",
    "\n",
    "print(\"Training TFT baseline...\")\n",
    "\n",
    "# === ç”¨ã€Œç¶“é scaling çš„å¼µé‡ã€æ‹¼å›å…¨é•·ï¼Œç¢ºä¿èˆ‡å¾ŒçºŒ tft_trend(val_X) å°ºåº¦ä¸€è‡´ ===\n",
    "# train/val/test çš„åˆ‡åˆ†æ˜¯æ²¿æ™‚é–“åˆ‡ï¼Œæ‰€ä»¥ç›´æ¥æŒ‰æ™‚é–“ä¸²æ¥å³å¯\n",
    "y_all = torch.cat([train_y, val_y, test_y], dim=0).squeeze(-1).cpu().numpy()  # (T, N)\n",
    "x_all = torch.cat([train_X, val_X, test_X], dim=0).cpu().numpy()              # (T, N, F)\n",
    "\n",
    "T_full = x_all.shape[0]\n",
    "N      = x_all.shape[1]\n",
    "F      = x_all.shape[2]\n",
    "\n",
    "# Build pandas DataFrames for Darts\n",
    "time_index = pd.RangeIndex(start=0, stop=T_full, step=1)\n",
    "target_df  = pd.DataFrame(\n",
    "    y_all,  # å·²ç¶“æ˜¯ (T, N)\n",
    "    index=time_index,\n",
    "    columns=[f\"y_loc_{i}\" for i in range(N)]\n",
    ")\n",
    "\n",
    "cont_np       = x_all.reshape(T_full, N * F)\n",
    "locs_expanded = np.tile(locs.astype(np.float32), (T_full, 1))\n",
    "cov_df = pd.DataFrame(\n",
    "    np.concatenate([cont_np, locs_expanded], axis=1),\n",
    "    index=time_index,\n",
    "    columns=[f\"x{j}_loc_{i}\" for i in range(N) for j in range(F)] + [f\"loc_{i}\" for i in range(N)]\n",
    ")\n",
    "\n",
    "# Create TimeSeries\n",
    "target_ts    = TimeSeries.from_dataframe(target_df,  fill_missing_dates=False)\n",
    "covariate_ts = TimeSeries.from_dataframe(cov_df,     fill_missing_dates=False)\n",
    "\n",
    "# Train TFTï¼ˆT_train ç”¨ train_X é•·åº¦ï¼‰\n",
    "T_train = len(train_X)\n",
    "input_chunk = CFG.get('tft_input_chunk_length') or min(32, max(8, T_train // 4))\n",
    "tft_model = TFTModel(\n",
    "    input_chunk_length=input_chunk,\n",
    "    output_chunk_length=int(CFG['tft_output_chunk_length']),\n",
    "    hidden_size=int(CFG['tft_hidden_size']),\n",
    "    lstm_layers=int(CFG['tft_lstm_layers']),\n",
    "    num_attention_heads=int(CFG['tft_num_attention_heads']),\n",
    "    full_attention=bool(CFG['tft_full_attention']),\n",
    "    hidden_continuous_size=int(CFG['tft_hidden_continuous_size']),\n",
    "    batch_size=int(CFG['tft_batch_size']),\n",
    "    n_epochs=int(CFG['tft_n_epochs']),\n",
    "    optimizer_kwargs=CFG['tft_optimizer_kwargs'],\n",
    "    add_relative_index=True,\n",
    "    force_reset=True,\n",
    "    save_checkpoints=False,\n",
    "    random_state=int(CFG['seed']),\n",
    "    dropout = 0.1\n",
    ")\n",
    "tft_model.fit(\n",
    "    series=target_ts[:T_train],\n",
    "    past_covariates=covariate_ts[:T_train],\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Wrap TFT as trend model for Spatial Adapter\n",
    "tft_wrapper = TFTWrapper(tft_model=tft_model, num_locations=N, num_features=F)\n",
    "tft_trend = create_pretrained_trend_model(\n",
    "    pretrained_model=tft_wrapper,\n",
    "    input_shape=(None, N, F),   # â† è¼¸å…¥ï¼šT x N x F\n",
    "    output_shape=(None, N, 1),  # â† è¼¸å‡ºï¼šT x N x 1\n",
    "    device=tft_trend.to(DEVICE)\n",
    ")\n",
    "\n",
    "# Residual eigen-basis from validation residuals\n",
    "with torch.no_grad():\n",
    "    y_tft_val  = tft_trend(val_X.to(DEVICE))\n",
    "    y_tft_test = tft_trend(test_X.to(DEVICE))\n",
    "\n",
    "# âœ… å£“æˆ 2D å†åšå…±è®Šç•°\n",
    "residuals_val = (val_y.to(DEVICE) - y_tft_val).squeeze(-1)  # (T_val, N)\n",
    "covariance_matrix = residuals_val.T @ residuals_val         # (N, N)\n",
    "K = CFG[\"latent_dim\"]\n",
    "eigenvectors = torch.linalg.eigh(covariance_matrix).eigenvectors[:, -K:]  # top-K\n",
    "\n",
    "tft_basis = SpatialBasisLearner(CFG[\"n_locations\"], K).to(DEVICE)\n",
    "tft_basis.basis.data.copy_(eigenvectors)\n",
    "\n",
    "# TFT metrics\n",
    "rmse_tft_val,  mae_tft_val,  r2_tft_val  = compute_metrics(val_y.to(DEVICE),  y_tft_val)\n",
    "rmse_tft_test, mae_tft_test, r2_tft_test = compute_metrics(test_y.to(DEVICE), y_tft_test)\n",
    "\n",
    "print(f\"TFT Validation - RMSE: {rmse_tft_val:.4f}, RÂ²: {r2_tft_val:.4f}\")\n",
    "print(f\"TFT Test       - RMSE: {rmse_tft_test:.4f}, RÂ²: {r2_tft_test:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3285ba2",
   "metadata": {},
   "source": [
    "## 5. Main Experiment Function\n",
    "å­˜æª”å¾seedæ”¹ç‚ºTFT_seed, \n",
    " å‘¼å« OLS çš„å‡½å¼æ”¹æˆå‘¼å« TFT å‡½å¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d03e369",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_one_experiment(dataset_seed: int, n_trials: int = 30):\n",
    "    \"\"\"Run a complete experiment for one dataset seed (TFT baseline + Spatial Adapter).\"\"\"\n",
    "    import copy  # ç‚ºäº† deepcopy trend/basis\n",
    "\n",
    "    log_root = Path(\"runs\") / f\"seed_{dataset_seed}\"\n",
    "    log_root.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # ---- Generate data for this seed ----\n",
    "    cat_features, cont_features, targets = generate_time_synthetic_data(\n",
    "        locs=locs,\n",
    "        n_time_steps=CFG[\"n_time_steps\"],\n",
    "        noise_std=CFG[\"noise_std\"],\n",
    "        eigenvalue=CFG[\"eigenvalue\"],\n",
    "        eta_rho=0.8,\n",
    "        f_rho=0.6,\n",
    "        global_mean=50.0,\n",
    "        feature_noise_std=0.1,\n",
    "        non_linear_strength=0.2,\n",
    "        seed=dataset_seed\n",
    "    )\n",
    "\n",
    "    # ---- Prepare datasets with scaling (æ²¿ç”¨ä½ åŸæœ¬ 0.7/0.15 åˆ‡åˆ†) ----\n",
    "    train_dataset, val_dataset, test_dataset, preprocessor = prepare_all_with_scaling(\n",
    "        cat_features=cat_features,\n",
    "        cont_features=cont_features,\n",
    "        targets=targets,\n",
    "        train_ratio=0.7,\n",
    "        val_ratio=0.15,\n",
    "        feature_scaler_type=\"standard\",\n",
    "        target_scaler_type=\"standard\",\n",
    "        fit_on_train_only=True\n",
    "    )\n",
    "    train_loader = DataLoader(train_dataset, batch_size=SPATIAL_CONFIG.training.batch_size, shuffle=True)\n",
    "\n",
    "    _, train_X, train_y = train_dataset.tensors\n",
    "    _, val_X,   val_y   = val_dataset.tensors\n",
    "    _, test_X,  test_y  = test_dataset.tensors\n",
    "\n",
    "    # ---- Shapes ----\n",
    "    T_full = cont_features.shape[0]\n",
    "    N      = cont_features.shape[1]\n",
    "    F      = train_X.shape[-1]\n",
    "\n",
    "    # ---- TFT Baselineï¼ˆå–ä»£ OLSï¼‰----\n",
    "    print(\"Training TFT baseline...\")\n",
    "    time_index = pd.RangeIndex(start=0, stop=T_full, step=1)\n",
    "\n",
    "    target_df = pd.DataFrame(\n",
    "        targets.reshape(T_full, N),\n",
    "        index=time_index,\n",
    "        columns=[f\"y_loc_{i}\" for i in range(N)]\n",
    "    )\n",
    "    cont_np        = cont_features.reshape(T_full, N * F)\n",
    "    locs_expanded  = np.tile(locs.astype(np.float32), (T_full, 1))\n",
    "    cov_df = pd.DataFrame(\n",
    "        np.concatenate([cont_np, locs_expanded], axis=1),\n",
    "        index=time_index,\n",
    "        columns=[f\"x{j}_loc_{i}\" for i in range(N) for j in range(F)] + [f\"loc_{i}\" for i in range(N)]\n",
    "    )\n",
    "\n",
    "    target_ts    = TimeSeries.from_dataframe(target_df, fill_missing_dates=False)\n",
    "    covariate_ts = TimeSeries.from_dataframe(cov_df,   fill_missing_dates=False)\n",
    "\n",
    "    T_train = len(train_X)\n",
    "    input_chunk = CFG.get('tft_input_chunk_length') or min(64, max(8, T_train // 4))\n",
    "    tft_model = TFTModel(\n",
    "        input_chunk_length=input_chunk,\n",
    "        output_chunk_length=int(CFG.get('tft_output_chunk_length', 1)),\n",
    "        hidden_size=int(CFG.get('tft_hidden_size', 64)),\n",
    "        n_epochs=int(CFG.get('tft_n_epochs', 30)),\n",
    "        dropout=float(CFG.get('tft_dropout', 0.1)),\n",
    "        batch_size=int(CFG.get('tft_batch_size', CFG.get('batch_size', 64))),\n",
    "        random_state=int(CFG.get('seed', 42)),\n",
    "        add_relative_index=True,\n",
    "        force_reset=True,\n",
    "        save_checkpoints=False,\n",
    "    )\n",
    "    tft_model.fit(\n",
    "        series=target_ts[:T_train],\n",
    "        past_covariates=covariate_ts[:T_train],\n",
    "        verbose=True\n",
    "    )\n",
    "\n",
    "    # Wrap TFT as trend model for Spatial Adapter\n",
    "    tft_wrapper = TFTWrapper(tft_model=tft_model, num_locations=N, num_features=F)\n",
    "    trend_base = create_pretrained_trend_model(\n",
    "        pretrained_model=tft_wrapper,\n",
    "        input_shape=(None, N, F),\n",
    "        device=DEVICE\n",
    "    )\n",
    "\n",
    "    # Baseline metrics\n",
    "    with torch.no_grad():\n",
    "        y_tft_val  = trend_base(val_X.to(DEVICE))\n",
    "        y_tft_test = trend_base(test_X.to(DEVICE))\n",
    "    rmse_tft,  mae_tft,  r2_tft    = compute_metrics(val_y.to(DEVICE),  y_tft_val)\n",
    "    rmse_tft_t, mae_tft_t, r2_tft_t = compute_metrics(test_y.to(DEVICE), y_tft_test)\n",
    "\n",
    "    # ---- ç”¨ TFT é©—è­‰æ®˜å·®åˆå§‹åŒ–ç©ºé–“åŸºåº•ï¼ˆtop-K eigenvectorsï¼‰----\n",
    "    with torch.no_grad():\n",
    "        resid_val = val_y.to(DEVICE) - y_tft_val\n",
    "    covM = resid_val.T @ resid_val\n",
    "    K = CFG[\"latent_dim\"]\n",
    "    eigvecs = torch.linalg.eigh(covM).eigenvectors[:, -K:]  # top-K\n",
    "\n",
    "    basis_init = SpatialBasisLearner(N, K).to(DEVICE)\n",
    "    basis_init.basis.data.copy_(eigvecs)\n",
    "\n",
    "    # ---- æ¸…ç©º cacheï¼Œæº–å‚™ bootstrap ----\n",
    "    cache.clear()\n",
    "    clear_gpu_memory()\n",
    "\n",
    "    # ---- Bootstrap: tau1=tau2=0ï¼ˆUnregularizedï¼‰----\n",
    "    boot_trend = copy.deepcopy(trend_base).to(DEVICE)\n",
    "    boot_basis = SpatialBasisLearner(N, K).to(DEVICE)\n",
    "    boot_basis.basis.data.copy_(basis_init.basis.data)\n",
    "\n",
    "    boot_writer = SummaryWriter(log_dir=log_root / \"bootstrap\")\n",
    "    boot = SpatialNeuralAdapter(\n",
    "        boot_trend,\n",
    "        boot_basis,\n",
    "        train_loader,\n",
    "        val_cont=val_X.to(DEVICE),\n",
    "        val_y=val_y.to(DEVICE),\n",
    "        locs=locs,\n",
    "        config=SPATIAL_CONFIG,\n",
    "        device=DEVICE,\n",
    "        writer=boot_writer,\n",
    "        tau1=0.0,\n",
    "        tau2=0.0,\n",
    "    )\n",
    "    boot.pretrain_trend(epochs=5)\n",
    "    boot.init_basis_dense()\n",
    "    boot.run()\n",
    "    cache.store(0.0, 0.0, boot_trend.state_dict(), boot_basis.state_dict())\n",
    "    boot_writer.close()\n",
    "\n",
    "    # Unreg predictions\n",
    "    y_boot_val  = boot.predict(val_X.to(DEVICE),  val_y.to(DEVICE))\n",
    "    rmse_boot,  mae_boot,  r2_boot  = compute_metrics(val_y.to(DEVICE),  y_boot_val)\n",
    "    y_boot_test = boot.predict(test_X.to(DEVICE), test_y.to(DEVICE))\n",
    "    rmse_boot_t, mae_boot_t, r2_boot_t = compute_metrics(test_y.to(DEVICE), y_boot_test)\n",
    "\n",
    "    # Clean up bootstrap models\n",
    "    del boot_trend, boot_basis, boot\n",
    "    clear_gpu_memory()\n",
    "\n",
    "    # ---- Optuna objectiveï¼ˆæœå°‹ tau1, tau2ï¼‰----\n",
    "    def objective(trial):\n",
    "        dev  = DEVICE\n",
    "        tau1 = trial.suggest_float(\"tau1\", 1e-4, 1e8, log=True)\n",
    "        tau2 = trial.suggest_float(\"tau2\", 1e-4, 1e8, log=True)\n",
    "\n",
    "        clear_gpu_memory()\n",
    "\n",
    "        trend = copy.deepcopy(trend_base).to(dev)\n",
    "        basis = SpatialBasisLearner(N, K).to(dev)\n",
    "        basis.basis.data.copy_(basis_init.basis.data)\n",
    "\n",
    "        # è‹¥ cache å…§æœ‰é„°è¿‘çš„èµ·é»ï¼Œè¼‰å…¥\n",
    "        cache.load_nearest(trend, basis, tau1, tau2)\n",
    "\n",
    "        writer = SummaryWriter(log_dir=log_root / f\"trial_{trial.number:03d}\")\n",
    "        trainer = SpatialNeuralAdapter(\n",
    "            trend,\n",
    "            basis,\n",
    "            train_loader,\n",
    "            val_cont=val_X.to(dev),\n",
    "            val_y=val_y.to(dev),\n",
    "            locs=locs,\n",
    "            config=SPATIAL_CONFIG,\n",
    "            device=dev,\n",
    "            writer=writer,\n",
    "            tau1=tau1,\n",
    "            tau2=tau2,\n",
    "        )\n",
    "        trainer.pretrain_trend(epochs=3)\n",
    "        trainer.init_basis_dense()\n",
    "        trainer.run()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            y_pred = trainer.predict(val_X.to(dev), val_y.to(dev))\n",
    "        rmse, mae, r2 = compute_metrics(val_y.to(dev), y_pred)\n",
    "\n",
    "        trial.set_user_attr(\"rmse\", rmse)\n",
    "        trial.set_user_attr(\"mae\", mae)\n",
    "        trial.set_user_attr(\"r2\", r2)\n",
    "\n",
    "        writer.close()\n",
    "        cache.store(tau1, tau2, trend.state_dict(), basis.state_dict())\n",
    "\n",
    "        del trend, basis, trainer, y_pred\n",
    "        clear_gpu_memory()\n",
    "\n",
    "        return rmse\n",
    "\n",
    "    study = optuna.create_study(\n",
    "        study_name=f\"spatial_adapter_ds{dataset_seed}\",\n",
    "        direction=\"minimize\",\n",
    "        sampler=optuna.samplers.TPESampler(),\n",
    "        pruner=MedianPruner(n_warmup_steps=5),\n",
    "        load_if_exists=False,\n",
    "    )\n",
    "    study.optimize(objective, n_trials=n_trials, n_jobs=1)\n",
    "\n",
    "    # ---- Best results ----\n",
    "    best     = study.best_trial\n",
    "    rmse_opt = best.user_attrs[\"rmse\"]\n",
    "    mae_opt  = best.user_attrs[\"mae\"]\n",
    "    r2_opt   = best.user_attrs[\"r2\"]\n",
    "    tau1_opt = best.params[\"tau1\"]\n",
    "    tau2_opt = best.params[\"tau2\"]\n",
    "    best_no  = best.number\n",
    "\n",
    "    # ---- Test best modelï¼ˆç”¨ cache ä¸­çš„æœ€ä½³æ¬Šé‡é‚„åŸ trend/basisï¼Œåšç°¡å–®æŠ•å½±è©•ä¼°ï¼‰----\n",
    "    dev_best = DEVICE\n",
    "    trend_best = copy.deepcopy(trend_base).to(dev_best)\n",
    "    basis_best = SpatialBasisLearner(N, K).to(dev_best)\n",
    "    # å¾ cache é‚„åŸï¼ˆè‹¥ä¸å­˜åœ¨æœƒ KeyErrorï¼›æ­£å¸¸ä¾†èªªå·² storeï¼‰\n",
    "    sd_t, sd_b = cache.cache[(tau1_opt, tau2_opt)]\n",
    "    trend_best.load_state_dict(sd_t)\n",
    "    basis_best.load_state_dict(sd_b)\n",
    "\n",
    "    trend_best.eval()\n",
    "    basis_best.eval()\n",
    "    with torch.no_grad():\n",
    "        X_test = test_X.to(dev_best)\n",
    "        y_test = test_y.to(dev_best)\n",
    "        y_trend = trend_best(X_test)\n",
    "        # å°‡æ®˜å·®æŠ•å½±åˆ°åŸºåº•å­ç©ºé–“ï¼Œå†åŠ å›è¶¨å‹¢ï¼ˆèˆ‡ä½ åŸæœ¬åšæ³•ä¸€è‡´ï¼‰\n",
    "        residual = y_test - y_trend\n",
    "        y_basis  = (residual @ basis_best.basis) @ basis_best.basis.T\n",
    "        y_reg_test = y_trend + y_basis\n",
    "    rmse_test, mae_test, r2_test = compute_metrics(y_test, y_reg_test)\n",
    "\n",
    "    # ---- Write results to CSV ----\n",
    "    csv_path = Path(\"metrics_summary.csv\")\n",
    "    write_header = not csv_path.exists()\n",
    "    with csv_path.open(\"a\", newline=\"\") as f:\n",
    "        w = csv.writer(f)\n",
    "        if write_header:\n",
    "            w.writerow([\n",
    "                \"seed\", \"model\", \"trial\", \"tau1\", \"tau2\",\n",
    "                \"rmse_val\", \"mae_val\", \"r2_val\",\n",
    "                \"rmse_test\", \"mae_test\", \"r2_test\"\n",
    "            ])\n",
    "\n",
    "        # Baselineï¼ˆTFTï¼‰\n",
    "        w.writerow([\n",
    "            dataset_seed, \"TFT\", \"\", \"\", \"\",\n",
    "            f\"{rmse_tft:.6f}\", f\"{mae_tft:.6f}\", f\"{r2_tft:.6f}\",\n",
    "            f\"{rmse_tft_t:.6f}\", f\"{mae_tft_t:.6f}\", f\"{r2_tft_t:.6f}\"\n",
    "        ])\n",
    "        # Unregularized\n",
    "        w.writerow([\n",
    "            dataset_seed, \"Unreg\", \"\", \"0\", \"0\",\n",
    "            f\"{rmse_boot:.6f}\", f\"{mae_boot:.6f}\", f\"{r2_boot:.6f}\",\n",
    "            f\"{rmse_boot_t:.6f}\", f\"{mae_boot_t:.6f}\", f\"{r2_boot_t:.6f}\"\n",
    "        ])\n",
    "        # Regularized\n",
    "        w.writerow([\n",
    "            dataset_seed, \"Reg\", best_no, f\"{tau1_opt:.6g}\", f\"{tau2_opt:.6g}\",\n",
    "            f\"{rmse_opt:.6f}\", f\"{mae_opt:.6f}\", f\"{r2_opt:.6f}\",\n",
    "            f\"{rmse_test:.6f}\", f\"{mae_test:.6f}\", f\"{r2_test:.6f}\"\n",
    "        ])\n",
    "\n",
    "    print(\n",
    "        f\"Dataset {dataset_seed}:  \"\n",
    "        f\"TFT RMSE={rmse_tft:.3f} | \"\n",
    "        f\"Unreg RMSE={rmse_boot:.3f} | \"\n",
    "        f\"Reg RMSE={rmse_opt:.3f} (test {rmse_test:.3f})\"\n",
    "    )\n",
    "\n",
    "    # ç‚ºäº†ç›¸å®¹å¤–éƒ¨ç¨‹å¼è‹¥ä»å– 'ols' keyï¼Œé€™è£¡æ²¿ç”¨ 'ols'ï¼Œå…§å®¹æ˜¯ TFT æŒ‡æ¨™\n",
    "    return {\n",
    "        'ols':   {'rmse_val': rmse_tft,  'rmse_test': rmse_tft_t,  'r2_val': r2_tft,  'r2_test': r2_tft_t},\n",
    "        'unreg': {'rmse_val': rmse_boot, 'rmse_test': rmse_boot_t, 'r2_val': r2_boot, 'r2_test': r2_boot_t},\n",
    "        'reg':   {'rmse_val': rmse_opt,  'rmse_test': rmse_test,   'r2_val': r2_opt,  'r2_test': r2_test,\n",
    "                  'tau1': tau1_opt, 'tau2': tau2_opt}\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a6642f",
   "metadata": {},
   "source": [
    "## 6. Run Full Experiment Suite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ababa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = []\n",
    "for seed in range(EXPERIMENT_TRIALS_CONFIG['seed_range_start'], EXPERIMENT_TRIALS_CONFIG['seed_range_end']):\n",
    "    print(f\"\\nStarting experiment for seed {seed}\")\n",
    "    results = run_one_experiment(seed, n_trials=EXPERIMENT_TRIALS_CONFIG['n_trials_per_seed'])\n",
    "    all_results.append(results)\n",
    "    cache.clear()\n",
    "    clear_gpu_memory()\n",
    "    print(f\"âœ… Completed seed {seed}\")\n",
    "\n",
    "print(\"\\nğŸ‰ All experiments completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0388ee",
   "metadata": {},
   "source": [
    "## 7. Results Analysis and Visualization\n",
    "\n",
    "é‚„æœªå®Œå…¨æ”¹å®Œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f2a423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load results\n",
    "results_df = pd.read_csv(\"metrics_summary.csv\")\n",
    "print(\"ğŸ“Š Results Summary (mean across seeds):\")\n",
    "print(results_df.groupby('model')[['rmse_val', 'rmse_test', 'r2_val', 'r2_test']].mean())\n",
    "\n",
    "# Plot comparison\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# RMSE comparison\n",
    "sns.boxplot(data=results_df, x='model', y='rmse_val', ax=axes[0,0])\n",
    "axes[0,0].set_title('Validation RMSE'); axes[0,0].set_ylabel('RMSE'); axes[0,0].grid(True, alpha=0.3)\n",
    "\n",
    "sns.boxplot(data=results_df, x='model', y='rmse_test', ax=axes[0,1])\n",
    "axes[0,1].set_title('Test RMSE'); axes[0,1].set_ylabel('RMSE'); axes[0,1].grid(True, alpha=0.3)\n",
    "\n",
    "# RÂ² comparison\n",
    "sns.boxplot(data=results_df, x='model', y='r2_val', ax=axes[1,0])\n",
    "axes[1,0].set_title('Validation RÂ²'); axes[1,0].set_ylabel('RÂ²'); axes[1,0].grid(True, alpha=0.3)\n",
    "\n",
    "sns.boxplot(data=results_df, x='model', y='r2_test', ax=axes[1,1])\n",
    "axes[1,1].set_title('Test RÂ²'); axes[1,1].set_ylabel('RÂ²'); axes[1,1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout(); plt.show()\n",
    "\n",
    "# Show best hyperparameters for regularized model\n",
    "reg_results = results_df[results_df['model'] == 'Reg']\n",
    "print(\"\\nğŸ”§ Best Hyperparameters for Regularized Model (first 10 rows):\")\n",
    "print(reg_results[['tau1', 'tau2', 'rmse_val', 'rmse_test']].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance comparison summary\n",
    "print(\"=== Performance Comparison Summary ===\")\n",
    "tft_mean_rmse   = results_df[results_df['model'] == 'TFT']['rmse_test'].mean()\n",
    "unreg_mean_rmse = results_df[results_df['model'] == 'Unreg']['rmse_test'].mean()\n",
    "reg_mean_rmse   = results_df[results_df['model'] == 'Reg']['rmse_test'].mean()\n",
    "\n",
    "print(f\"TFT (baseline) - Mean Test RMSE: {tft_mean_rmse:.4f}\")\n",
    "print(f\"Unregularized  - Mean Test RMSE: {unreg_mean_rmse:.4f} ({(1 - unreg_mean_rmse/tft_mean_rmse)*100:.1f}% improvement)\")\n",
    "print(f\"Regularized    - Mean Test RMSE: {reg_mean_rmse:.4f} ({(1 - reg_mean_rmse/tft_mean_rmse)*100:.1f}% improvement)\")\n",
    "\n",
    "from scipy import stats\n",
    "wide = results_df.pivot_table(index='seed', columns='model', values='rmse_test', aggfunc='mean')\n",
    "paired = wide[['TFT', 'Reg']].dropna()\n",
    "t_stat, p_value = stats.ttest_rel(paired['TFT'], paired['Reg'])\n",
    "\n",
    "print(f\"\\nStatistical Test (TFT vs Regularized): t={t_stat:.4f}, p={p_value:.4f}, \"\n",
    "      f\"significant: {'Yes' if p_value < 0.05 else 'No'}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geospatial-neural-adapter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
