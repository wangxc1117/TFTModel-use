{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "tft-spatial-adapter-demo",
   "metadata": {},
   "source": [
    "# TFT + Spatial Adapter Integration Demo\n",
    "\n",
    "This notebook demonstrates how to integrate a pretrained TFT model into the Spatial Adapter framework using the PretrainedTrendModel wrapper.\n",
    "\n",
    "The key insight is that we can use any pretrained model as the backbone f_Œ∏ in the spatial adapter equation:\n",
    "Y(t,s) = g(f_Œ∏(x(t,s)) + Œ¶(s)^T Œ∑(t)) + Œµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from typing import Tuple, Dict, Any\n",
    "import time\n",
    "\n",
    "# Darts imports for TFT\n",
    "from darts import TimeSeries\n",
    "from darts.models import TFTModel\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "# Local imports\n",
    "from geospatial_neural_adapter import (\n",
    "    SpatialNeuralAdapter,\n",
    "    SpatialBasisLearner,\n",
    "    compute_metrics,\n",
    ")\n",
    "from geospatial_neural_adapter.models.pretrained_trend_model import (\n",
    "    PretrainedTrendModel,\n",
    "    create_pretrained_trend_model,\n",
    ")\n",
    "from geospatial_neural_adapter.models.spatial_adapter import (\n",
    "    SpatialAdapter,\n",
    "    create_spatial_adapter,\n",
    ")\n",
    "from geospatial_neural_adapter.data.generators import generate_time_synthetic_data\n",
    "from geospatial_neural_adapter.data.preprocessing import prepare_all_with_scaling, denormalize_predictions\n",
    "from geospatial_neural_adapter.models.wrapper_examples.tft_wrapper import TFTWrapper\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"‚úÖ All imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data-generation",
   "metadata": {},
   "source": [
    "## 1. Data Generation\n",
    "\n",
    "We'll use the same synthetic data generator to create a consistent dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generate-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic temporal data with meaningful correlations\n",
    "print(\"Generating correlated temporal synthetic data...\")\n",
    "\n",
    "n_locations = 50\n",
    "n_time_steps = 200\n",
    "locations = np.linspace(-5, 5, n_locations)\n",
    "noise_std = 0.1\n",
    "eigenvalue = 2.0\n",
    "\n",
    "cat_features, cont_features, targets = generate_time_synthetic_data(\n",
    "    locs=locations,\n",
    "    n_time_steps=n_time_steps,\n",
    "    noise_std=noise_std,\n",
    "    eigenvalue=eigenvalue,\n",
    "    eta_rho=0.8,\n",
    "    f_rho=0.6,\n",
    "    global_mean=50.0,\n",
    "    feature_noise_std=0.1,\n",
    "    non_linear_strength=0.2,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "print(f\"Data shapes: {cont_features.shape}, {targets.shape}\")\n",
    "print(f\"Original targets - Mean: {targets.mean():.2f}, Std: {targets.std():.2f}\")\n",
    "print(f\"Original targets - Range: {targets.min():.2f} to {targets.max():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preprocessing",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preprocess-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare datasets with automatic scaling\n",
    "print(\"Preparing datasets with automatic scaling...\")\n",
    "\n",
    "train_dataset, val_dataset, test_dataset, preprocessor = prepare_all_with_scaling(\n",
    "    cat_features=cat_features,\n",
    "    cont_features=cont_features,\n",
    "    targets=targets,\n",
    "    train_ratio=0.7,\n",
    "    val_ratio=0.15,\n",
    "    feature_scaler_type=\"standard\",\n",
    "    target_scaler_type=\"standard\",\n",
    "    fit_on_train_only=True\n",
    ")\n",
    "\n",
    "train_cat, train_cont, train_targets = train_dataset.tensors\n",
    "val_cat, val_cont, val_targets = val_dataset.tensors\n",
    "test_cat, test_cont, test_targets = test_dataset.tensors\n",
    "\n",
    "print(f\"Dataset sizes: {len(train_dataset)}, {len(val_dataset)}, {len(test_dataset)}\")\n",
    "\n",
    "# Get data dimensions\n",
    "T, N, F = cont_features.shape\n",
    "print(f\"Original data shape: {cont_features.shape}\")\n",
    "print(f\"Number of locations: {N}\")\n",
    "print(f\"Number of features: {F}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tft-model",
   "metadata": {},
   "source": [
    "## 3. Create and Train TFT Model\n",
    "\n",
    "We'll create a TFT model and train it on our data. In practice, you might load a pretrained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create-tft",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for TFT model\n",
    "print(\"Preparing data for TFT model...\")\n",
    "\n",
    "# Use scaled data from preprocessing\n",
    "train_cont_np = train_cont.numpy().astype(np.float32)\n",
    "train_targets_np = train_targets.numpy().astype(np.float32)\n",
    "val_cont_np = val_cont.numpy().astype(np.float32)\n",
    "val_targets_np = val_targets.numpy().astype(np.float32)\n",
    "test_cont_np = test_cont.numpy().astype(np.float32)\n",
    "test_targets_np = test_targets.numpy().astype(np.float32)\n",
    "\n",
    "# Combine all scaled data for TFT\n",
    "cont_np = np.concatenate([train_cont_np, val_cont_np, test_cont_np], axis=0)\n",
    "targets_np = np.concatenate([train_targets_np, val_targets_np, test_targets_np], axis=0)\n",
    "T_full, N, p = cont_np.shape\n",
    "\n",
    "print(f\"Full data shape: T={T_full}, N={N}, p={p}\")\n",
    "print(f\"Using SCALED data (mean={targets_np.mean():.4f}, std={targets_np.std():.4f})\")\n",
    "\n",
    "# Create time index\n",
    "time_index = pd.date_range(\"2020-01-01\", periods=T_full, freq=\"D\")\n",
    "\n",
    "# Create multivariate time series\n",
    "target_df = pd.DataFrame(targets_np, index=time_index, \n",
    "                        columns=[f\"loc_{i}\" for i in range(N)])\n",
    "\n",
    "# Create covariates with spatial information\n",
    "locations_expanded = np.tile(locations, (T_full, 1))\n",
    "cov_full = np.concatenate([cont_np.reshape(T_full, -1), locations_expanded], axis=1).astype(np.float32)\n",
    "\n",
    "covariate_df = pd.DataFrame(cov_full, index=time_index,\n",
    "                           columns=[f\"cov_{j}_loc_{i}\" for i in range(N) for j in range(p)] + \n",
    "                                   [f\"spatial_loc_{i}\" for i in range(N)])\n",
    "\n",
    "# Create TimeSeries objects\n",
    "target_ts = TimeSeries.from_dataframe(target_df, fill_missing_dates=True)\n",
    "covariate_ts = TimeSeries.from_dataframe(covariate_df, fill_missing_dates=True)\n",
    "\n",
    "print(f\"Target TimeSeries shape: {target_ts.values().shape}\")\n",
    "print(f\"Covariate TimeSeries shape: {covariate_ts.values().shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "train-tft",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TFT model configuration (lighter for demo)\n",
    "tft_config = {\n",
    "    \"input_chunk_length\": min(32, T_full // 8),\n",
    "    \"output_chunk_length\": 1,\n",
    "    \"n_epochs\": 20,  # Reduced for demo\n",
    "    \"hidden_size\": 32,\n",
    "    \"num_attention_heads\": 2,\n",
    "    \"dropout\": 0.1,\n",
    "    \"random_state\": 42,\n",
    "    \"force_reset\": True,\n",
    "    \"add_relative_index\": True,\n",
    "    \"use_static_covariates\": False,\n",
    "}\n",
    "\n",
    "print(\"TFT Configuration:\")\n",
    "for key, value in tft_config.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# Create and train TFT model\n",
    "print(\"Creating and training TFT model...\")\n",
    "\n",
    "training_cutoff = int(0.8 * T_full)\n",
    "print(f\"Training cutoff: {training_cutoff}\")\n",
    "\n",
    "tft_model = TFTModel(\n",
    "    input_chunk_length=tft_config[\"input_chunk_length\"],\n",
    "    output_chunk_length=tft_config[\"output_chunk_length\"],\n",
    "    n_epochs=tft_config[\"n_epochs\"],\n",
    "    hidden_size=tft_config[\"hidden_size\"],\n",
    "    num_attention_heads=tft_config[\"num_attention_heads\"],\n",
    "    dropout=tft_config[\"dropout\"],\n",
    "    random_state=tft_config[\"random_state\"],\n",
    "    force_reset=tft_config[\"force_reset\"],\n",
    "    add_relative_index=tft_config[\"add_relative_index\"],\n",
    "    use_static_covariates=tft_config[\"use_static_covariates\"],\n",
    "    pl_trainer_kwargs={\n",
    "        \"accelerator\": \"gpu\" if torch.cuda.is_available() else \"cpu\",\n",
    "        \"devices\": -1,\n",
    "        \"enable_progress_bar\": True,\n",
    "        \"enable_model_summary\": False,\n",
    "        \"enable_checkpointing\": False,\n",
    "        \"max_epochs\": tft_config[\"n_epochs\"],\n",
    "    },\n",
    ")\n",
    "\n",
    "# Train TFT model\n",
    "start_time = time.time()\n",
    "tft_model.fit(\n",
    "    target_ts[:training_cutoff], \n",
    "    past_covariates=covariate_ts[:training_cutoff],\n",
    "    verbose=True\n",
    ")\n",
    "tft_training_time = time.time() - start_time\n",
    "print(f\"TFT training completed in {tft_training_time:.2f}s\")\n",
    "\n",
    "# Save the trained TFT model\n",
    "tft_model_path = \"tft_spatial_adapter_model.pth\"\n",
    "print(f\"Saving TFT model to {tft_model_path}\")\n",
    "tft_model.save(tft_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tft-wrapper",
   "metadata": {},
   "source": [
    "## 4. Create TFT Wrapper for Spatial Adapter\n",
    "\n",
    "Now we'll wrap the trained TFT model using the dedicated `TFTWrapper` from the library, which provides the necessary interface for integrating TFT models into the spatial adapter framework.\n",
    "\n",
    "The key improvement is that the `TFTWrapper` handles the conversion between tensor formats and TimeSeries formats required by darts, and provides the `parameters()` method needed by `PretrainedTrendModel`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create-tft-wrapper",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TFT wrapper for spatial adapter\n",
    "print(\"Creating TFT wrapper for spatial adapter...\")\n",
    "\n",
    "# Use the dedicated TFT wrapper from the library\n",
    "\n",
    "# Create TFT wrapper using the dedicated module\n",
    "tft_wrapper = TFTWrapper(\n",
    "    tft_model=tft_model,\n",
    "    num_locations=N,\n",
    "    num_features=F\n",
    ")\n",
    "\n",
    "# Create pretrained trend model wrapper\n",
    "tft_trend_model = create_pretrained_trend_model(\n",
    "    pretrained_model=tft_wrapper,  # Use the wrapper instead of tft_model directly\n",
    "    input_shape=(None, N, F),  # (batch_size, num_locations, num_features)\n",
    "    output_shape=(None, N),    # (batch_size, num_locations)\n",
    "    model_type=\"custom\",\n",
    "    freeze_backbone=True,      # Keep TFT frozen initially\n",
    "    add_residual_head=True,    # Add trainable residual head\n",
    "    residual_hidden_dim=64,    # Smaller for demo\n",
    "    dropout_rate=0.1,\n",
    ")\n",
    "\n",
    "print(f\"TFT trend model parameters: {sum(p.numel() for p in tft_trend_model.parameters()):,}\")\n",
    "print(f\"TFT trend model trainable parameters: {sum(p.numel() for p in tft_trend_model.residual_parameters()):,}\")\n",
    "\n",
    "# Test the wrapper\n",
    "print(\"\\nTesting TFT wrapper...\")\n",
    "test_input = torch.randn(2, N, F)  # (batch_size, num_locations, num_features)\n",
    "with torch.no_grad():\n",
    "    try:\n",
    "        test_output = tft_trend_model(test_input)\n",
    "        print(f\"Test input shape: {test_input.shape}\")\n",
    "        print(f\"Test output shape: {test_output.shape}\")\n",
    "        print(\"‚úÖ TFT wrapper test successful!\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå TFT wrapper test failed: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spatial-adapter",
   "metadata": {},
   "source": [
    "## 5. Create Spatial Adapter with TFT Backbone\n",
    "\n",
    "Now we'll create the complete spatial adapter using the TFT model as the backbone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create-spatial-adapter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create spatial adapter with TFT backbone\n",
    "print(\"Creating spatial adapter with TFT backbone...\")\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Create spatial basis learner\n",
    "spatial_basis = SpatialBasisLearner(\n",
    "    num_locations=N,\n",
    "    latent_dim=10,  # K << N\n",
    "    pca_init=None,\n",
    ")\n",
    "\n",
    "# Create locations tensor\n",
    "locations_tensor = torch.tensor(locations.reshape(-1, 1), dtype=torch.float32)\n",
    "\n",
    "# Create complete spatial adapter\n",
    "spatial_adapter = create_spatial_adapter(\n",
    "    trend_model=tft_trend_model,\n",
    "    num_locations=N,\n",
    "    latent_dim=10,\n",
    "    locations=locations_tensor,\n",
    "    factor_computation_method=\"residual_projection\",\n",
    "    output_activation=\"identity\",\n",
    "    noise_variance=1.0,\n",
    "    enable_uncertainty=True,\n",
    ")\n",
    "\n",
    "print(f\"Spatial adapter parameters: {sum(p.numel() for p in spatial_adapter.parameters()):,}\")\n",
    "print(f\"Spatial basis parameters: {sum(p.numel() for p in spatial_adapter.spatial_basis.parameters()):,}\")\n",
    "\n",
    "# Test the spatial adapter\n",
    "print(\"\\nTesting spatial adapter...\")\n",
    "test_input = torch.randn(2, N, F)\n",
    "with torch.no_grad():\n",
    "    try:\n",
    "        test_output, test_info = spatial_adapter(test_input, return_components=True)\n",
    "        print(f\"Test input shape: {test_input.shape}\")\n",
    "        print(f\"Test output shape: {test_output.shape}\")\n",
    "        print(f\"Components: {list(test_info.keys())}\")\n",
    "        print(\"‚úÖ Spatial adapter test successful!\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Spatial adapter test failed: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "training",
   "metadata": {},
   "source": [
    "## 6. Train Spatial Adapter with TFT Backbone\n",
    "\n",
    "Now we'll train the spatial adapter using the ADMM framework, with the TFT model providing the initial trend predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "train-spatial-adapter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for training\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "print(\"Preparing data for spatial adapter training...\")\n",
    "\n",
    "# Create data loader\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Training configuration (lighter for demo)\n",
    "config = {\n",
    "    \"rho\": 5.0,\n",
    "    \"dual_momentum\": 0.2,\n",
    "    \"max_iters\": 50,  # Reduced for demo\n",
    "    \"min_outer\": 25,\n",
    "    \"lr_mu\": 1e-3,\n",
    "    \"batch_size\": 64,\n",
    "    \"phi_every\": 5,\n",
    "    \"phi_freeze\": 25,\n",
    "    \"tol\": 1e-4,\n",
    "    \"adaptive_rho_mu\": 10.0,\n",
    "    \"adaptive_rho_tau_inc\": 2.0,\n",
    "    \"adaptive_rho_tau_dec\": 2.0,\n",
    "    \"matrix_reg\": 1e-6,\n",
    "    \"irl1_max_iters\": 10,\n",
    "    \"irl1_eps\": 1e-6,\n",
    "    \"irl1_tol\": 5e-4,\n",
    "    \"coord_threshold\": 1e-12,\n",
    "    \"avoid_zero_eps\": 1e-12,\n",
    "    \"pretrain_epochs\": 3,  # Reduced for demo\n",
    "    \"use_mixed_precision\": True,\n",
    "}\n",
    "\n",
    "print(\"Training Configuration:\")\n",
    "for key, value in config.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# Create trainer with TFT backbone\n",
    "print(\"\\nCreating SpatialNeuralAdapter with TFT backbone...\")\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter(\"./logs/tft_spatial_adapter_demo\")\n",
    "\n",
    "trainer = SpatialNeuralAdapter(\n",
    "    trend=tft_trend_model,  # Use TFT wrapper instead of regular TrendModel\n",
    "    basis=spatial_basis,\n",
    "    train_loader=train_loader,\n",
    "    val_cont=val_cont,\n",
    "    val_y=val_targets,\n",
    "    locs=locations,\n",
    "    config=config,\n",
    "    device=device,\n",
    "    writer=writer,\n",
    "    tau1=0.1,\n",
    "    tau2=0.1,\n",
    ")\n",
    "\n",
    "# Print configuration\n",
    "trainer.print_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "run-training",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run training\n",
    "print(\"Starting ADMM training with TFT backbone...\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Note: We skip pretraining since TFT is already trained\n",
    "print(\"Skipping trend pretraining (TFT already trained)...\")\n",
    "\n",
    "# Initialize basis\n",
    "print(\"Initializing spatial basis...\")\n",
    "trainer.init_basis_dense()\n",
    "\n",
    "# Run ADMM training\n",
    "print(\"Starting ADMM training...\")\n",
    "best_val = trainer.run()\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "print(f\"Training completed in {training_time:.2f}s\")\n",
    "print(f\"Best validation RMSE: {best_val:.6f}\")\n",
    "\n",
    "# Close tensorboard writer\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "evaluation",
   "metadata": {},
   "source": [
    "## 7. Model Evaluation and Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "evaluate-models",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate both TFT-only and TFT+Spatial Adapter\n",
    "print(\"Evaluating models...\")\n",
    "\n",
    "# 1. TFT-only evaluation\n",
    "print(\"\\n1. TFT-only evaluation:\")\n",
    "try:\n",
    "    # Use TFT wrapper directly for evaluation (more reliable than raw TFT model)\n",
    "    tft_wrapper.eval()\n",
    "    \n",
    "    # Get validation data\n",
    "    val_start = len(train_dataset)\n",
    "    val_end = val_start + len(val_dataset)\n",
    "    \n",
    "    # Prepare validation features and targets\n",
    "    val_features = torch.tensor(cont_np[val_start:val_end], dtype=torch.float32)  # Shape: (val_steps, N, F)\n",
    "    val_targets_eval = torch.tensor(targets_np[val_start:val_end], dtype=torch.float32)  # Shape: (val_steps, N)\n",
    "    \n",
    "    # Use TFT wrapper to get predictions\n",
    "    with torch.no_grad():\n",
    "        tft_predictions = []\n",
    "        for i in range(len(val_features)):\n",
    "            # Get prediction for this time step\n",
    "            input_tensor = val_features[i:i+1]  # Shape: (1, N, F)\n",
    "            pred = tft_wrapper(input_tensor)  # Shape: (1, N)\n",
    "            tft_predictions.append(pred.squeeze(0))  # Shape: (N,)\n",
    "        \n",
    "        tft_pred_tensor = torch.stack(tft_predictions)  # Shape: (val_steps, N)\n",
    "    \n",
    "    # Flatten for metrics computation\n",
    "    tft_pred_scaled = tft_pred_tensor.numpy().flatten()\n",
    "    tft_true_scaled = val_targets_eval.numpy().flatten()\n",
    "    \n",
    "    # Compute metrics on standardized scale\n",
    "    tft_rmse_std = np.sqrt(np.mean((tft_true_scaled - tft_pred_scaled) ** 2))\n",
    "    tft_mae_std = np.mean(np.abs(tft_true_scaled - tft_pred_scaled))\n",
    "    tft_r2_std = 1 - np.sum((tft_true_scaled - tft_pred_scaled) ** 2) / np.sum((tft_true_scaled - tft_true_scaled.mean()) ** 2)\n",
    "    \n",
    "    print(f\"TFT-only - RMSE: {tft_rmse_std:.6f}, MAE: {tft_mae_std:.6f}, R¬≤: {tft_r2_std:.6f}\")\n",
    "    print(f\"TFT predictions shape: {tft_pred_tensor.shape}\")\n",
    "    print(f\"TFT targets shape: {val_targets_eval.shape}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"TFT-only evaluation failed: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    tft_rmse_std = tft_mae_std = tft_r2_std = np.inf\n",
    "\n",
    "# 2. TFT + Spatial Adapter evaluation\n",
    "print(\"\\n2. TFT + Spatial Adapter evaluation:\")\n",
    "\n",
    "trainer.trend.eval()\n",
    "trainer.basis.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Get predictions from spatial adapter\n",
    "    y_pred_std = trainer.predict(val_cont.to(device), val_targets.to(device))\n",
    "    \n",
    "    # Compute metrics on standardized scale\n",
    "    rmse_std, mae_std, r2_std = compute_metrics(val_targets.to(device), y_pred_std)\n",
    "    \n",
    "    print(f\"TFT+Spatial - RMSE: {rmse_std:.6f}, MAE: {mae_std:.6f}, R¬≤: {r2_std:.6f}\")\n",
    "    \n",
    "    # Denormalize predictions for original scale evaluation\n",
    "    y_pred_denorm = denormalize_predictions(y_pred_std.cpu().numpy(), preprocessor)\n",
    "    val_targets_denorm = denormalize_predictions(val_targets.cpu().numpy(), preprocessor)\n",
    "    \n",
    "    # Compute metrics on original scale\n",
    "    rmse_denorm = np.sqrt(np.mean((val_targets_denorm - y_pred_denorm) ** 2))\n",
    "    mae_denorm = np.mean(np.abs(val_targets_denorm - y_pred_denorm))\n",
    "    \n",
    "    # R-squared on original scale\n",
    "    ss_res_denorm = np.sum((val_targets_denorm - y_pred_denorm) ** 2)\n",
    "    ss_tot_denorm = np.sum((val_targets_denorm - val_targets_denorm.mean()) ** 2)\n",
    "    r2_denorm = 1 - (ss_res_denorm / ss_tot_denorm)\n",
    "    \n",
    "    print(f\"TFT+Spatial (denorm) - RMSE: {rmse_denorm:.6f}, MAE: {mae_denorm:.6f}, R¬≤: {r2_denorm:.6f}\")\n",
    "\n",
    "# 3. Comparison\n",
    "print(\"\\n3. Model Comparison:\")\n",
    "if tft_rmse_std != np.inf:\n",
    "    improvement = (tft_rmse_std - rmse_std) / tft_rmse_std * 100\n",
    "    print(f\"RMSE improvement: {improvement:.2f}%\")\n",
    "    \n",
    "    r2_improvement = (r2_std - tft_r2_std) * 100\n",
    "    print(f\"R¬≤ improvement: {r2_improvement:.2f}%\")\n",
    "else:\n",
    "    print(\"Could not compute improvement (TFT evaluation failed)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "visualization",
   "metadata": {},
   "source": [
    "## 8. Results Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visualize-results",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive visualizations\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Use denormalized data for visualization\n",
    "val_y_np = val_targets_denorm\n",
    "y_pred_np = y_pred_denorm\n",
    "\n",
    "# Plot 1: Predictions vs Actual scatter plot\n",
    "axes[0, 0].scatter(val_y_np.flatten(), y_pred_np.flatten(), alpha=0.5, s=20)\n",
    "axes[0, 0].plot([val_y_np.min(), val_y_np.max()], \n",
    "                [val_y_np.min(), val_y_np.max()], 'r--', linewidth=2, label='Perfect Prediction')\n",
    "axes[0, 0].set_title('TFT + Spatial Adapter: Predictions vs Actual')\n",
    "axes[0, 0].set_xlabel('Actual Values')\n",
    "axes[0, 0].set_ylabel('Predicted Values')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Spatial pattern comparison\n",
    "sample_idx = 0\n",
    "axes[0, 1].plot(locations, val_y_np[sample_idx], 'o-', label='Actual', alpha=0.7, linewidth=2, markersize=4)\n",
    "axes[0, 1].plot(locations, y_pred_np[sample_idx], 's-', label='Predicted', alpha=0.7, linewidth=2, markersize=4)\n",
    "axes[0, 1].set_title('Spatial Pattern Comparison')\n",
    "axes[0, 1].set_xlabel('Location')\n",
    "axes[0, 1].set_ylabel('Target Value')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Residuals analysis\n",
    "residuals = val_y_np.flatten() - y_pred_np.flatten()\n",
    "axes[1, 0].scatter(y_pred_np.flatten(), residuals, alpha=0.5, s=20)\n",
    "axes[1, 0].axhline(y=0, color='r', linestyle='--', alpha=0.7)\n",
    "axes[1, 0].set_title('Residuals vs Predicted Values')\n",
    "axes[1, 0].set_xlabel('Predicted Values')\n",
    "axes[1, 0].set_ylabel('Residuals')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: Residuals distribution\n",
    "axes[1, 1].hist(residuals, bins=30, alpha=0.7, edgecolor='black')\n",
    "axes[1, 1].set_title('Residuals Distribution')\n",
    "axes[1, 1].set_xlabel('Residual Value')\n",
    "axes[1, 1].set_ylabel('Frequency')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spatial-basis",
   "metadata": {},
   "source": [
    "## 9. Spatial Basis Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analyze-basis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the learned spatial basis\n",
    "print(\"Analyzing learned spatial basis...\")\n",
    "\n",
    "# Get the basis matrix\n",
    "basis_matrix = trainer.basis.basis.detach().cpu().numpy()\n",
    "print(f\"Basis matrix shape: {basis_matrix.shape}\")\n",
    "print(f\"Basis norm: {np.linalg.norm(basis_matrix):.4f}\")\n",
    "\n",
    "# Visualize the basis\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i in range(min(6, basis_matrix.shape[1])):\n",
    "    # Plot basis vector as spatial pattern\n",
    "    axes[i].plot(locations, basis_matrix[:, i], 'o-', linewidth=2, markersize=4)\n",
    "    axes[i].set_title(f'Spatial Basis {i+1}')\n",
    "    axes[i].set_xlabel('Location')\n",
    "    axes[i].set_ylabel('Basis Value')\n",
    "    axes[i].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Basis statistics\n",
    "print(\"\\nBasis Statistics:\")\n",
    "print(f\"Mean: {basis_matrix.mean():.4f}\")\n",
    "print(f\"Std: {basis_matrix.std():.4f}\")\n",
    "print(f\"Min: {basis_matrix.min():.4f}\")\n",
    "print(f\"Max: {basis_matrix.max():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": [
    "## 10. Performance Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "final-summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print final summary\n",
    "print(\"=\" * 60)\n",
    "print(\"TFT + SPATIAL ADAPTER INTEGRATION SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Device: {device}\")\n",
    "print(f\"TFT training time: {tft_training_time:.2f}s\")\n",
    "print(f\"Spatial adapter training time: {training_time:.2f}s\")\n",
    "print(f\"Total training time: {tft_training_time + training_time:.2f}s\")\n",
    "print()\n",
    "print(\"MODEL PARAMETERS:\")\n",
    "print(f\"TFT model parameters: {sum(p.numel() for p in tft_trend_model.parameters()):,}\")\n",
    "print(f\"TFT trainable parameters: {sum(p.numel() for p in tft_trend_model.parameters() if p.requires_grad):,}\")\n",
    "print(f\"Spatial adapter parameters: {sum(p.numel() for p in trainer.basis.parameters()):,}\")\n",
    "print(f\"Spatial adapter trainable parameters: {sum(p.numel() for p in trainer.basis.parameters() if p.requires_grad):,}\")\n",
    "print()\n",
    "print(\"PERFORMANCE:\")\n",
    "print(f\"TFT-only RMSE: {tft_rmse_std:.6f}\")\n",
    "print(f\"TFT+Spatial RMSE: {rmse_std:.6f}\")\n",
    "print(f\"TFT-only MAE: {tft_mae_std:.6f}\")\n",
    "print(f\"TFT+Spatial MAE: {mae_std:.6f}\")\n",
    "print(f\"TFT-only R¬≤: {tft_r2_std:.6f}\")\n",
    "print(f\"TFT+Spatial R¬≤: {r2_std:.6f}\")\n",
    "print()\n",
    "print(\"IMPROVEMENTS:\")\n",
    "if tft_rmse_std != np.inf:\n",
    "    rmse_improvement = (tft_rmse_std - rmse_std) / tft_rmse_std * 100\n",
    "    r2_improvement = (r2_std - tft_r2_std) * 100\n",
    "    print(f\"RMSE improvement: {rmse_improvement:.2f}%\")\n",
    "    print(f\"R¬≤ improvement: {r2_improvement:.2f}%\")\n",
    "else:\n",
    "    print(\"Could not compute improvements (TFT evaluation failed)\")\n",
    "print()\n",
    "print(\"KEY INSIGHTS:\")\n",
    "print(\"1. TFT provides temporal modeling capabilities\")\n",
    "print(\"2. Spatial adapter adds spatial structure modeling\")\n",
    "print(\"3. Combined approach leverages both temporal and spatial patterns\")\n",
    "print(\"4. Uncertainty quantification available through spatial adapter\")\n",
    "print(\"5. Dedicated TFTWrapper handles format conversion and interface compatibility\")\n",
    "print()\n",
    "print(\"FILES SAVED:\")\n",
    "print(f\"TFT model: {tft_model_path}\")\n",
    "print(f\"Tensorboard logs: ./logs/tft_spatial_adapter_demo\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\n‚úÖ TFT + Spatial Adapter integration completed successfully!\")\n",
    "print(\"üí° Run 'tensorboard --logdir ./logs/tft_spatial_adapter_demo' to view training progress\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geospatial-neural-adapter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
