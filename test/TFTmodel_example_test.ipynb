{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef7fe4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import torch \n",
    "from tqdm import tqdm\n",
    "from darts import TimeSeries\n",
    "from darts.models import TFTModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e9533b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_data_folder(folder):\n",
    "    return os.path.exists(folder) and os.path.isdir(folder)\n",
    "\n",
    "def generate_date_range(start_date, end_date):\n",
    "    \"\"\"\n",
    "    Generate a list of dates from start_date to end_date.\n",
    "    \"\"\"\n",
    "    return pd.date_range(start=start_date, end=end_date, freq='D').strftime('%Y%m%d').tolist()\n",
    "\n",
    "def load_data(file_path):\n",
    "    \"\"\"\n",
    "    Load data from a NetCDF file.\n",
    "    \"\"\"\n",
    "    if os.path.exists(file_path):\n",
    "        return xr.open_dataset(file_path)\n",
    "    else:\n",
    "        raise FileNotFoundError(f'File not found: {file_path}')\n",
    "\n",
    "\n",
    "# main program\n",
    "## check data folder\n",
    "data_folder = f'nc4'\n",
    "if check_data_folder(data_folder):\n",
    "    print(f'Data folder found: {data_folder}')\n",
    "else:\n",
    "    raise FileNotFoundError(f'Data folder not found: {data_folder}')\n",
    "\n",
    "## load data\n",
    "start_date = '2024-01-01'\n",
    "end_date = '2024-01-14'\n",
    "date_list = generate_date_range(start_date, end_date)\n",
    "\n",
    "## get location and shape\n",
    "path = os.path.join(data_folder, f'M2T1NXFLX.5.12.4%3AMERRA2_400.tavg1_2d_flx_Nx.{date_list[0]}.nc4.dap.nc4')\n",
    "nc4_data = load_data(path)\n",
    "lat = nc4_data['lat'].values\n",
    "lon = nc4_data['lon'].values\n",
    "shape = nc4_data['TLML'].shape\n",
    "total_locations = shape[1] * shape[2]\n",
    "\n",
    "## combine data\n",
    "# 預先讀取第一個檔案以取得 shape 資訊\n",
    "sample_path = os.path.join(data_folder, f'M2T1NXFLX.5.12.4%3AMERRA2_400.tavg1_2d_flx_Nx.{date_list[0]}.nc4.dap.nc4')\n",
    "sample_data = load_data(sample_path)\n",
    "shape_per_file = sample_data['TLML'].shape   # e.g. (24, 361, 576)\n",
    "time_per_file = len(sample_data['time'])\n",
    "\n",
    "# 預先配置 array（假設每天 24 筆資料）\n",
    "total_samples = len(date_list)\n",
    "combined = np.empty((total_samples * shape_per_file[0], *shape_per_file[1:]), dtype=np.float32)\n",
    "time_list = np.empty(total_samples * time_per_file, dtype=sample_data['time'].dtype)\n",
    "\n",
    "# 批次載入並填入預分配的 array\n",
    "for i, date in enumerate(tqdm(date_list, desc=\"Combining\")):\n",
    "    path = os.path.join(data_folder, f'M2T1NXFLX.5.12.4%3AMERRA2_400.tavg1_2d_flx_Nx.{date}.nc4.dap.nc4')\n",
    "    nc4_data = load_data(path)\n",
    "\n",
    "    start = i * shape_per_file[0]\n",
    "    end = (i + 1) * shape_per_file[0]\n",
    "\n",
    "    combined[start:end] = nc4_data['TLML'].values\n",
    "    time_list[start:end] = nc4_data['time'].values\n",
    "\n",
    "print(f'Combined data shape: {combined.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15047b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 123\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "# to Rcode y1 cell × time\n",
    "ntot, nlat, nlon = combined.shape\n",
    "ncell = nlat * nlon\n",
    "y1 = combined.reshape(ntot, ncell).T\n",
    "\n",
    "# to Rcode gg cell × (lon, lat)\n",
    "lon_grid, lat_grid = np.meshgrid(lon, lat)\n",
    "gg = np.vstack([lon_grid.ravel(), lat_grid.ravel()]).T\n",
    "\n",
    "# 抽樣\n",
    "ncell, ntot = y1.shape\n",
    "T = 200\n",
    "m = 1000\n",
    "pickm = np.random.choice(ncell, size=m, replace=False)\n",
    "y_sub   = y1[pickm, :]      # (m, ntot)\n",
    "gg_sub  = gg[pickm, :]      # (m, 2)\n",
    "\n",
    "# DatetimeIndex\n",
    "time_index = pd.to_datetime(time_list)\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    y_sub.T,\n",
    "    index=time_index,\n",
    "    columns=[f\"cell_{i}\" for i in range(m)]\n",
    ")\n",
    "\n",
    "# 經緯度 DataFrame\n",
    "static_df = pd.DataFrame(\n",
    "    gg_sub,\n",
    "    index=df.columns,\n",
    "    columns=[\"lon\",\"lat\"]\n",
    ")\n",
    "\n",
    "# to TimeSeries\n",
    "series = TimeSeries.from_dataframe(df, static_covariates=static_df)\n",
    "train  = series[:T]   # T 1-200\n",
    "true_201 = df.iloc[T].values  # 201期真值，shape=(m,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c8ae8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks import TQDMProgressBar, EarlyStopping, ModelCheckpoint\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "progress_callback = TQDMProgressBar(refresh_rate = 1)\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor = \"val_loss\",\n",
    "    patience = 10,\n",
    "    mode = \"min\",\n",
    "    verbose = True\n",
    ")\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor=\"val_loss\",\n",
    "    save_top_k=1,\n",
    "    mode=\"min\",\n",
    "    filename=\"tft-{epoch:02d}-{val_loss:.2f}\",\n",
    "    dirpath=\"checkpoint\"\n",
    ")\n",
    "\n",
    "logger = TensorBoardLogger(\"tb_logs\", name=\"tft\")\n",
    "\n",
    "pl_trainer_kwargs = {\n",
    "    # 裝置與精度\n",
    "    \"accelerator\":                     \"gpu\",        # \"cpu\" / \"gpu\"  \n",
    "    \"devices\":                         [0],          # CPU:1 / GPU:[0] or 1       \n",
    "\n",
    "    # 訓練長度\n",
    "    \"max_epochs\":                      300,          # 最多跑幾個 epoch\n",
    "    \"min_epochs\":                      10,           # 最少跑幾個 epoch\n",
    "\n",
    "    # batch 限制（提升除錯速度）\n",
    "    \"limit_train_batches\":             1.0,          # 比例 (0.0~1.0) 或整數\n",
    "    \"limit_val_batches\":               1.0,          # 同上\n",
    "    \"val_check_interval\":              1.0,          # 每多少 epoch (float) 或 batch (float<1)\n",
    "\n",
    "    # 日誌與 sanity check\n",
    "    \"log_every_n_steps\":               10,           # 每多少 batch 印一次 log\n",
    "    \"num_sanity_val_steps\":            2,            # 開始前跑多少驗證 batch\n",
    "\n",
    "    # 梯度與更新\n",
    "    \"gradient_clip_val\":               0.1,          # 梯度裁剪值\n",
    "    \"gradient_clip_algorithm\":         \"norm\",       # \"norm\" 或 \"value\"\n",
    "    \"accumulate_grad_batches\":         1,            # 幾個 batch 累積一次更新\n",
    "\n",
    "    # 檢查點、Callback、Logger\n",
    "    \"enable_checkpointing\":            True,         # 啟用 ModelCheckpoint\n",
    "    \"callbacks\":                       [              # Lightning Callback list\n",
    "        progress_callback,\n",
    "        early_stop,\n",
    "        checkpoint_callback\n",
    "    ],\n",
    "    \"logger\":                          logger,       # Lightning Logger\n",
    "\n",
    "    # 其他選項\n",
    "    \"reload_dataloaders_every_n_epochs\":  0,         # 幾 epoch 後重載 DataLoader\n",
    "    \"fast_dev_run\":                      False,      # 同時跑 train/val/test 各一 batch\n",
    "    \"benchmark\":                         False,      # cuDNN 找最佳配置 (需和 deterministic 搭配)\n",
    "    \"profiler\":                          \"simple\",   # \"simple\" / \"advanced\" / 自訂\n",
    "    \"enable_model_summary\":              True        # 啟動時印模型摘要\n",
    "}\n",
    "\n",
    "# TFTModel\n",
    "model = TFTModel(\n",
    "    input_chunk_length  = 24,  # 模型每次觀察過去  期資料\n",
    "    output_chunk_length = 1,   # 預測下 1 期\n",
    "    hidden_size         = 64,\n",
    "    lstm_layers         = 1,\n",
    "    num_attention_heads = 4,\n",
    "    dropout             = 0.1,\n",
    "    random_state        = SEED,\n",
    "    add_relative_index = True,\n",
    "    add_encoders         = {\n",
    "      'cyclic': {'past': ['hour']},\n",
    "      'position': {'past': ['relative'], 'future': ['relative']}\n",
    "    },\n",
    "    pl_trainer_kwargs    = pl_trainer_kwargs\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3ede06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and predict\n",
    "train  = series[:160]     \n",
    "val    = series[160:200]   \n",
    "model.fit( train, val_series = val)\n",
    "forecast_201 = model.predict(n=1)      # shape=(1,5000)\n",
    "pred_201     = forecast_201.values()[0]\n",
    "\n",
    "# MSPE\n",
    "mask     = ~np.isnan(true_201)\n",
    "mspe_py  = np.mean((pred_201[mask] - true_201[mask])**2)\n",
    "rmspe_py = np.sqrt(mspe_py)\n",
    "print(f\"Python TFTModel Next-step MSPE = {mspe_py:.6f} | RMSPE = {rmspe_py:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84cc8e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
